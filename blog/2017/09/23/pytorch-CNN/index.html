<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>pytorch:CNN卷积神经网络 · Kaige Dong&#x27;s Site</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="卷积神经网络目前被广泛地用在图片识别上, 已经有层出不穷的应用, 一步一步做一个分析手写数字的 CNN 吧."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="pytorch:CNN卷积神经网络 · Kaige Dong&#x27;s Site"/><meta property="og:type" content="website"/><meta property="og:url" content="https://kaigedong.github.io/Linux-best-practice/blog/2017/09/23/pytorch-CNN"/><meta property="og:description" content="卷积神经网络目前被广泛地用在图片识别上, 已经有层出不穷的应用, 一步一步做一个分析手写数字的 CNN 吧."/><meta property="og:image" content="https://kaigedong.github.io/Linux-best-practice/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://kaigedong.github.io/Linux-best-practice/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/Linux-best-practice/img/favicon.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><link rel="alternate" type="application/atom+xml" href="https://kaigedong.github.io/Linux-best-practice/blog/atom.xml" title="Kaige Dong&#x27;s Site Blog ATOM Feed"/><link rel="alternate" type="application/rss+xml" href="https://kaigedong.github.io/Linux-best-practice/blog/feed.xml" title="Kaige Dong&#x27;s Site Blog RSS Feed"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/Linux-best-practice/js/scrollSpy.js"></script><link rel="stylesheet" href="/Linux-best-practice/css/main.css"/><script src="/Linux-best-practice/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/Linux-best-practice/"><img class="logo" src="/Linux-best-practice/img/favicon.ico" alt="Kaige Dong&#x27;s Site"/><h2 class="headerTitleWithLogo">Kaige Dong&#x27;s Site</h2></a><a href="/Linux-best-practice/versions"><h3>0.1.5</h3></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class=""><a href="/Linux-best-practice/docs/doc1" target="_self">Docs</a></li><li class=""><a href="/Linux-best-practice/docs/doc4" target="_self">API</a></li><li class=""><a href="/Linux-best-practice/help" target="_self">Help</a></li><li class="siteNavGroupActive"><a href="/Linux-best-practice/blog/" target="_self">Blog</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>All blog posts</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">All blog posts</h3><ul class=""><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/09/20/scrapy_to_search_engine_Introduction">1.爬虫课程的介绍</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/04/09/Python_sorting">Python排序算法</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/04/09/Learn_make_Donot_starve_mods">学习制作饥荒mod</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/04/09/Donot_starve_mod1">饥荒mod1</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/04/09/python_virtual_env">virtualenv 和 pyenv的使用</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/16/Wuenda_machine_learning">吴恩达机器学习笔记</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/13/Django-Apache-wsgi-_deploy">Django+Apache wsgi 部署</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/12/Apache-deploy-Django">Apache 部署 Django</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/09/pytorch-60min">PyTorch 60min教程</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/09/no_root_install_Apache">无root安装Apache</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/07/GIVEinstall">GIVE安装笔记</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/06/wali_v2ray">搬瓦工2: v2ray</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/08/16/Curses-python3-7">Curses_python3.7</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/05/12/wali_note">搬瓦工笔记1：ssr</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/19/DQN_5">强化学习实战：从零开始下五子棋</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/17/DQN_Sarsa">强化学习之Sarsa</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/17/DQN_Sarsa-lambda">增强学习之Sarsa(lambda)</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/16/DQN_Q-learning">深度学习02之Q-learning介绍</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/16/DQN">强化学习介绍与分类01</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/08/07_shadowsocks_settings">shadowsocks配置</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/07/19_shell_env_set/env-export">shell变量及进程及set,env,export</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/07/12_Perl/install_models">Perl安装模块与卸载</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/07/11_python_convert_exe_videos">python批量转换exe视频</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/09_no_root_install_MySQL">服务器无root安装MySQL</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/05/08_Macinstall_MySQL">Mac安装MySQL &amp; Ubuntu下安装MySQL记录</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/tmus">tmus指南</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/17_DQN_DQN">增强学习之DQN介绍</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/17_DQN2/Algo">增强学习之DQN算法</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/08/17python的decode/encode-与-r-b-u">python的decode/encode 与 r/b/u</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/08/17_golang_notes">golang笔记</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/12/09_unroot_install_UCSC_genome_browser">modele_name</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/08/13_Acer中Arch安装Secure/boot-EFI-设置">Acer中Arch安装Secure boot EFI 设置</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13_HTMLandCSS_basic_03">HTML与CSS基础03-Web框架与表单设计</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2019/08/20_Linux_crontab">Linux crontab定时任务</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/learn-git">learn-git</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/items2">items2技巧</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/chenwei_gene_A07-A09">陈巍学基因A07-A09</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/chenwei_gene_A01-A03">陈巍学基因A01-A03</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/chenwei_geneA04-A06">陈巍学基因A04-A06</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/boxplot">数据可视化之柱状图</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/begin_building_sites">开始建站Hexo+NexT</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/Hexo-NexT404pages">Hexo-NexT主题的404页面</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/HTMLandCSS_basic_01">HTML和CSS基础01-html的语法和基本结构文档设置标记</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2018/04/13/HTML_CSS_basic2">HTML和CSS基础02-图像超链接和表格</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/26/pig_exons">modele_name</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/26/Counting-known-microRNAs-in-five-easy-steps">Counting known microRNAs in five easy steps</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/26/R_214">R极客的情人节</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/25/Adapter-and-quality-trimming-of-illumina-data">Adapter and quality trimming of illumina data</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/23/pytorch_bach">pytorch批训练</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/23/pytorch-Optimizer">pytorch:Optimizer优化器</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/Linux-best-practice/blog/2017/09/23/pytorch-CNN">pytorch:CNN卷积神经网络</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/sync_server_files">同步服务器文件夹</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch07">pytorch07</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch06">pytorch06</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch05">pytorch05</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/Affymetrix">Affymetrix芯片原理</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch03">pytorch03</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch02">pytorch02</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch01">pytorch 学习笔记</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/matlab04">matlab04图像的增强处理</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/matlab03">matlab03图像的几何变换</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/matlab02">matlab02图像的点运算</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/matlab">matlab学习笔记01</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/WEB_frame">WEB框架</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/ChIP-seq-masc">ChIP-seq-macs</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/CSS">CSS层叠样式表</a></li><li class="navListItem"><a class="navItem" href="/Linux-best-practice/blog/2017/09/22/pytorch04">pytorch04</a></li></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer postContainer blogContainer"><div class="wrapper"><div class="lonePost"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle"><a href="/Linux-best-practice/blog/2017/09/23/pytorch-CNN">pytorch:CNN卷积神经网络</a></h1><p class="post-meta">September 23, 2017</p><div class="authorBlock"><p class="post-authorName"><a href="" target="_blank" rel="noreferrer noopener">woobamboo</a></p></div></header><div><span><p>卷积神经网络目前被广泛地用在图片识别上, 已经有层出不穷的应用, 一步一步做一个分析手写数字的 CNN 吧.</p>
<!--truncate-->
<h2><a class="anchor" aria-hidden="true" id="mnist手写数据"></a><a href="#mnist手写数据" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>MNIST手写数据</h2>
<pre><code class="hljs css language-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable
<span class="hljs-keyword">import</span> torch.utils.data <span class="hljs-keyword">as</span> Data
<span class="hljs-keyword">import</span> torchvision      <span class="hljs-comment"># 数据库模块</span>
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

torch.manual_seed(<span class="hljs-number">1</span>)    <span class="hljs-comment"># reproducible</span>

<span class="hljs-comment"># Hyper Parameters</span>
EPOCH = <span class="hljs-number">1</span>           <span class="hljs-comment"># 训练整批数据多少次, 为了节约时间, 我们只训练一次</span>
BATCH_SIZE = <span class="hljs-number">50</span>
LR = <span class="hljs-number">0.001</span>          <span class="hljs-comment"># 学习率</span>
DOWNLOAD_MNIST = <span class="hljs-literal">True</span>  <span class="hljs-comment"># 如果你已经下载好了mnist数据就写上 Fasle</span>


<span class="hljs-comment"># Mnist 手写数字</span>
train_data = torchvision.datasets.MNIST(
    root=<span class="hljs-string">'./mnist/'</span>,    <span class="hljs-comment"># 保存或者提取位置</span>
    train=<span class="hljs-literal">True</span>,  <span class="hljs-comment"># this is training data</span>
    transform=torchvision.transforms.ToTensor(),    <span class="hljs-comment"># 转换 PIL.Image or numpy.ndarray 成</span>
                                                    <span class="hljs-comment"># torch.FloatTensor (C x H x W), 训练的时候 normalize 成 [0.0, 1.0] 区间</span>
    download=DOWNLOAD_MNIST,          <span class="hljs-comment"># 没下载就下载, 下载了就不用再下了</span>
)
</code></pre>
<h3><a class="anchor" aria-hidden="true" id="一个数字的例子"></a><a href="#一个数字的例子" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>一个数字的例子</h3>
<pre><code class="hljs css language-python"><span class="hljs-comment"># plot one example</span>
print(train_data.train_data.size())                 <span class="hljs-comment"># (60000, 28, 28)</span>
print(train_data.train_labels.size())               <span class="hljs-comment"># (60000)</span>
plt.imshow(train_data.train_data[<span class="hljs-number">0</span>].numpy(), cmap=<span class="hljs-string">'gray'</span>)
plt.title(<span class="hljs-string">'%i'</span> % train_data.train_labels[<span class="hljs-number">0</span>])
plt.show()
</code></pre>
<p><img src="/Linux-best-practice/blog/assets/2017-09/figure_9.png" alt=""></p>
<p>黑色的地方的值都是0, 白色的地方值大于0.</p>
<p>同样, 我们除了训练数据, 还给一些测试数据, 测试看看它有没有训练好.</p>
<pre><code class="hljs css language-python">test_data = torchvision.datasets.MNIST(root=<span class="hljs-string">'./mnist/'</span>, train=<span class="hljs-literal">False</span>)

<span class="hljs-comment"># 批训练 50samples, 1 channel, 28x28 (50, 1, 28, 28)</span>
train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># 为了节约时间, 我们测试时只测试前2000个</span>
test_x = Variable(torch.unsqueeze(test_data.test_data, dim=<span class="hljs-number">1</span>), volatile=<span class="hljs-literal">True</span>).type(torch.FloatTensor)[:<span class="hljs-number">2000</span>]/<span class="hljs-number">255.</span>   <span class="hljs-comment"># shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)</span>
test_y = test_data.test_labels[:<span class="hljs-number">2000</span>]
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="cnn-模型"></a><a href="#cnn-模型" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>CNN 模型</h2>
<p>和以前一样, 我们用一个 class 来建立 CNN 模型. 这个 CNN 整体流程是 卷积(<code>Conv2d</code>) -&gt; 激励函数(<code>ReLU</code>) -&gt; 池化, 向下采样 (<code>MaxPooling</code>) -&gt; 再来一遍 -&gt; 展平多维的卷积成的特征图 -&gt; 接入全连接层 (<code>Linear</code>) -&gt; 输出</p>
<pre><code class="hljs css language-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CNN</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(CNN, self).__init__()
        self.conv1 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span>
            nn.Conv2d(
                in_channels=<span class="hljs-number">1</span>,      <span class="hljs-comment"># input height</span>
                out_channels=<span class="hljs-number">16</span>,    <span class="hljs-comment"># n_filters</span>
                kernel_size=<span class="hljs-number">5</span>,      <span class="hljs-comment"># filter size</span>
                stride=<span class="hljs-number">1</span>,           <span class="hljs-comment"># filter movement/step</span>
                padding=<span class="hljs-number">2</span>,      <span class="hljs-comment"># 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1</span>
            ),      <span class="hljs-comment"># output shape (16, 28, 28)</span>
            nn.ReLU(),    <span class="hljs-comment"># activation</span>
            nn.MaxPool2d(kernel_size=<span class="hljs-number">2</span>),    <span class="hljs-comment"># 在 2x2 空间里向下采样, output shape (16, 14, 14)</span>
        )
        self.conv2 = nn.Sequential(  <span class="hljs-comment"># input shape (1, 28, 28)</span>
            nn.Conv2d(<span class="hljs-number">16</span>, <span class="hljs-number">32</span>, <span class="hljs-number">5</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 14, 14)</span>
            nn.ReLU(),  <span class="hljs-comment"># activation</span>
            nn.MaxPool2d(<span class="hljs-number">2</span>),  <span class="hljs-comment"># output shape (32, 7, 7)</span>
        )
        self.out = nn.Linear(<span class="hljs-number">32</span> * <span class="hljs-number">7</span> * <span class="hljs-number">7</span>, <span class="hljs-number">10</span>)   <span class="hljs-comment"># fully connected layer, output 10 classes</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, x)</span>:</span>
        x = self.conv1(x)
        x = self.conv2(x)
        x = x.view(x.size(<span class="hljs-number">0</span>), <span class="hljs-number">-1</span>)   <span class="hljs-comment"># 展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span>
        output = self.out(x)
        <span class="hljs-keyword">return</span> output

cnn = CNN()
print(cnn)  <span class="hljs-comment"># net architecture</span>
<span class="hljs-string">"""
CNN (
  (conv1): Sequential (
    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU ()
    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (conv2): Sequential (
    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (1): ReLU ()
    (2): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  )
  (out): Linear (1568 -&gt; 10)
)
"""</span>
</code></pre>
<h2><a class="anchor" aria-hidden="true" id="训练"></a><a href="#训练" aria-hidden="true" class="hash-link"><svg class="hash-link-icon" aria-hidden="true" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>训练</h2>
<p>下面我们开始训练, 将 <code>x</code> <code>y</code> 都用 <code>Variable</code> 包起来, 然后放入 <code>cnn</code> 中计算 <code>output</code>, 最后再计算误差. 下面代码省略了计算精确度 <code>accuracy</code> 的部分。</p>
<pre><code class="hljs css language-python">optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   <span class="hljs-comment"># optimize all cnn parameters</span>
loss_func = nn.CrossEntropyLoss()   <span class="hljs-comment"># the target label is not one-hotted</span>
</code></pre>
<pre><code class="hljs css language-python"><span class="hljs-comment"># following function (plot_with_labels) is for visualization, can be ignored if not interested</span>
<span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> cm
<span class="hljs-keyword">try</span>: <span class="hljs-keyword">from</span> sklearn.manifold <span class="hljs-keyword">import</span> TSNE; HAS_SK = <span class="hljs-literal">True</span>
<span class="hljs-keyword">except</span>: HAS_SK = <span class="hljs-literal">False</span>; print(<span class="hljs-string">'Please install sklearn for layer visualization'</span>)
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_with_labels</span><span class="hljs-params">(lowDWeights, labels)</span>:</span>
    plt.cla()
    X, Y = lowDWeights[:, <span class="hljs-number">0</span>], lowDWeights[:, <span class="hljs-number">1</span>]
    <span class="hljs-keyword">for</span> x, y, s <span class="hljs-keyword">in</span> zip(X, Y, labels):
        c = cm.rainbow(int(<span class="hljs-number">255</span> * s / <span class="hljs-number">9</span>)); plt.text(x, y, s, backgroundcolor=c, fontsize=<span class="hljs-number">9</span>)
    plt.xlim(X.min(), X.max()); plt.ylim(Y.min(), Y.max()); plt.title(<span class="hljs-string">'Visualize last layer'</span>); plt.show(); plt.pause(<span class="hljs-number">0.01</span>)

plt.ion()
</code></pre>
<pre><code class="hljs css language-python"><span class="hljs-comment"># training and testing</span>
<span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> range(EPOCH):
    <span class="hljs-keyword">for</span> step, (x, y) <span class="hljs-keyword">in</span> enumerate(train_loader):   <span class="hljs-comment"># 分配 batch data, normalize x when iterate train_loader</span>
        b_x = Variable(x)   <span class="hljs-comment"># batch x</span>
        b_y = Variable(y)   <span class="hljs-comment"># batch y</span>

        output = cnn(b_x)               <span class="hljs-comment"># cnn output</span>
        loss = loss_func(output, b_y)   <span class="hljs-comment"># cross entropy loss</span>
        optimizer.zero_grad()           <span class="hljs-comment"># clear gradients for this training step</span>
        loss.backward()                 <span class="hljs-comment"># backpropagation, compute gradients</span>
        optimizer.step()                <span class="hljs-comment"># apply gradients</span>
        
        <span class="hljs-keyword">if</span> step % <span class="hljs-number">50</span> == <span class="hljs-number">0</span>:
            test_output, last_layer = cnn(test_x)
            pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].data.squeeze()
            accuracy = sum(pred_y == test_y) / float(test_y.size(<span class="hljs-number">0</span>))
            print(<span class="hljs-string">'Epoch: '</span>, epoch, <span class="hljs-string">'| train loss: %.4f'</span> % loss.data[<span class="hljs-number">0</span>], <span class="hljs-string">'| test accuracy: %.2f'</span> % accuracy)
            <span class="hljs-keyword">if</span> HAS_SK:
                <span class="hljs-comment"># Visualization of trained flatten layer (T-SNE)</span>
                tsne = TSNE(perplexity=<span class="hljs-number">30</span>, n_components=<span class="hljs-number">2</span>, init=<span class="hljs-string">'pca'</span>, n_iter=<span class="hljs-number">5000</span>)
                plot_only = <span class="hljs-number">500</span>
                low_dim_embs = tsne.fit_transform(last_layer.data.numpy()[:plot_only, :])
                labels = test_y.numpy()[:plot_only]
                plot_with_labels(low_dim_embs, labels)
plt.ioff()

<span class="hljs-string">"""
...
Epoch:  0 | train loss: 0.0306 | test accuracy: 0.97
Epoch:  0 | train loss: 0.0147 | test accuracy: 0.98
Epoch:  0 | train loss: 0.0427 | test accuracy: 0.98
Epoch:  0 | train loss: 0.0078 | test accuracy: 0.98
"""</span>
</code></pre>
<p>最后我们再来取10个数据, 看看预测的值到底对不对:</p>
<pre><code class="hljs css language-python">test_output = cnn(test_x[:<span class="hljs-number">10</span>])
pred_y = torch.max(test_output, <span class="hljs-number">1</span>)[<span class="hljs-number">1</span>].data.numpy().squeeze()
print(pred_y, <span class="hljs-string">'prediction number'</span>)
print(test_y[:<span class="hljs-number">10</span>].numpy(), <span class="hljs-string">'real number'</span>)

<span class="hljs-string">"""
[7 2 1 0 4 1 4 9 5 9] prediction number
[7 2 1 0 4 1 4 9 5 9] real number
"""</span>
</code></pre>
</span></div></div><div class="blogSocialSection"></div></div><div class="blog-recent"><a class="button" href="/Linux-best-practice/blog">Recent posts</a></div></div></div><nav class="onPageNav"><ul class="toc-headings"><li><a href="#mnist手写数据">MNIST手写数据</a><ul class="toc-headings"><li><a href="#一个数字的例子">一个数字的例子</a></li></ul></li><li><a href="#cnn-模型">CNN 模型</a></li><li><a href="#训练">训练</a></li></ul></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/Linux-best-practice/" class="nav-home"><img src="/Linux-best-practice/img/favicon.ico" alt="Kaige Dong&#x27;s Site" width="66" height="58"/></a><div><h5>Docs</h5><a href="/Linux-best-practice/docs/en/doc1.html">Getting Started (or other categories)</a><a href="/Linux-best-practice/docs/en/doc2.html">Guides (or other categories)</a><a href="/Linux-best-practice/docs/en/doc3.html">API Reference (or other categories)</a></div><div><h5>Community</h5><a href="/Linux-best-practice/en/users.html">User Showcase</a><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="/Linux-best-practice/blog">Blog</a><a href="https://github.com/">GitHub</a><a class="github-button" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/Linux-best-practice/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2019 Kaige Dong</section></footer></div></body></html>